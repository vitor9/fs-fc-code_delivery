:Para solucionar isso, trabalharemos com o Apache Kafka para o envio e recebimento de dados entre os sistemas.

P:Nao eh responsabilidade do servico backend persistir os dados no ElasticSearch. Logo, como armazenar as informacoes no ElasticSearch?
S:Utilizaremos o Kafka Connect, que tambem consumira os dados do simulador e fara a insercao no ElasticSearch.

P:Precisaremos exibir em tempo real a localizacao de cada entregador(deixar tudo dinamico, em tempo real).
S: Trabalharemos com websockets. Assim que o backend receber a informacao do Apache Kafka, ele enviara as pocies posicoes para o frontend via websocket.

O que eh WebSocket?
Eh uma forma de fazermos conexao TCP, do browser, com o servidor, para mantermos uma conexao persistente, ao inves de mandar e receber o tempo todo. Temos uma conexa, ela vai ficar persistente, para mandarmos e recebermos tudo dentro do mesmo canal de comunicacao, diret, entre o front e back. Ao inves de termos que mandar milhares requisicoes.

================================================ DINAMICA DO SISTEMA =============================================
Backend inicia o processo, simulador comeca a mandar as posicoes.
Via web-socket, o back vai comecar a mandar para o front, aonde esta o carrinho, para que o frontend pilote o carro para mostrar aonde o motorista esta rodando.

Simulador
O simulador vai ficar passando dados de long e latit, quais os dados da corrida que esta sendo enviada nesse momento.
Vamos utilizar o Apache Kafka para esses envios. Quando inicia uma corrida, o back fala, estou iniciando uma corrida tal aqui para la, ai o simulador acessa o kafka, pega a informacao

Queremos pegar esses dados e jogar no elasticsearch, com o Kafka Connect. Conforme o ismulador for mandando as informacoes para o Kafka, o Kafka COnnect vai pegar elas, que esta sendo enviada p/ o simulador,
vai pegar e jogar no elasticsearch. Os dados de cada posicao e tudo que esta acontecendo, vai ficar no elasticsearch.

Vamos poder consultar o elasticsearch, atraves do Kibana. O kibana eh um dashboard, que consegue acessar os dados do elasticsearch.

Essa estrutura eh escalavel para aguentar bastante tecnologia e aguenta muita requisicao.

Tecnologias a serem utilizadas:
- Simulador: GoLang. 
	Possui um sistema que facilita trabalhar com multi-threading. Vou ter que enviar para o Kafka diversas posicoes de diversas corridas ao mesmo tempo, simultaneamente, e isso o multi-thread ajuda muito.

- BackEnd: Nest.js e Mongo.
	Nest.js roda em cima do node, e eh especifico em trabalhar com microsservicos. Vai ter bastante facilidade com websocket, e fazer comunicacao com o Kafka e o MongoDB
	MongoDB vai ser o nosso mecanismo nao-relacional, de persistencia de dados.

- FrontEnd: React.
	Vamos utilizar a Material.UI para deixar a interface mais agradavel e simples, para trabalharmos.

- Kafka & Kafka Connect.
	Kafka vai ser o nosso servidor de Streaming de dados que recebe as informacoes e consegue prover em tempo real.
	O Connect, vai se conectar no Kafka e ira jogar as informacoes em diversos sistemas.

- ElasticSearch e Kibana.
	O kibana eh um dashboard, que consegue acessar os dados do elasticsearch.

- Docker e Kubernetes
	Docker vai nos ajudar a montar o ambiente tranquilo, para subirmos todas estas tecnologias com facilidade, ao inves de instalar tecnologia por tecnologia
	Kubernetes vai nos auxiliar com a orquestracao dos containers do Docker, para que subirmos os containers com mais praticidade.

- Istio, Kiali, Prometheus e Grafana
	Istio, servico de service mesh, vai monitorar todas as comunicacoes dos nossos sistemas, para monitorarmos tudo que esta acontecendo entre os nossos servicos utilizando o Kiali.
	Grafana, Vai se conectar com o sistemas que vai coletar as metricas, utilizando o Prometheus.
	
====================================================================================================================

=========================================== MAO NA MASSA ===========================================================

A tag "extra_hosts" no docker-compose, facilita pegar diversos sistemas em redes diferentes e coloca eles para se conversarem.
Por exemplo, quando subirmos o servico nosso Kafka com o docker-compose, vamos fazer o nosso sistema falar com o Kafka atraves da rede padrao do Docker.

Apos criar os nossos dockerfile e o docker-compose, subimos os containers utilizando o comando do docker-compose:
"
vitor@vtr-dsk:~/imersao-fs-fc/fs-fc-code_delivery/simulator$ docker-compose up -d
"
Apos subir nossos containers, podemos listar nossos containers com o docker-compose com o comando:
"
vitor@vtr-dsk:~/imersao-fs-fc/fs-fc-code_delivery/simulator$ docker-compose ps
  Name           Command        State   Ports
---------------------------------------------
simulator   tail -f /dev/null   Up    
"
Feito isso, podemos testar nosso container, entrando nele com o comando, passando o it(modo inteirativo) e o nome do nosso container:
"
vitor@vtr-dsk:~/imersao-fs-fc/fs-fc-code_delivery/simulator$ docker exec -it simulator bash
root@4cd9f1f92c31:/go/src# 
"
Ao listarmos o conteudo dentro do nosso container, vamos ver que esta de fato, compartilhando os mesmos arquivos na nossa maquina aonde estamos criando o projeto:
"
root@4cd9f1f92c31:/go/src# ls -la
total 20
drwxrwxr-x 3 1000 1000 4096 Apr  6 01:46 .
drwxrwxrwx 4 root root 4096 Apr  2 00:20 ..
drwxrwxr-x 2 1000 1000 4096 Apr  6 01:45 .idea
-rw-rw-r-- 1 1000 1000  172 Apr  6 01:45 Dockerfile
-rw-rw-r-- 1 1000 1000  164 Apr  6 01:46 docker-compose.yaml
"
O go possui uma ferramenta chamada de "go mod". Ele trabalha como se fosse um controlador de gerenciamento de versao de todos os pacotes externos utilizados no Go.
Vamos iniciar com o Go Mod para termos o controle de versao dos nossos pacotes:
"
root@4cd9f1f92c31:/go/src# go mod init github.com/vitor9/fs-fc-code_delivery
go: creating new go.mod: module github.com/vitor9/fs-fc-code_delivery
"
Conforme eu for add pacotes externos, ele vai colocando um require com os pacotes e versoes no arqv go.mod

Nosso sistema le rotas. Mandamos as posicoes delas.

Criamos o arquivo consumer.go. Ele vai ser responsavel por consumir e pegar os dados na nossa fila/topico do kafka.


Nosso metodo Produce, da classe producer.go, quando recebermos uma msg do Kafka, vamos pegar-la, vms converter ela, de um JSON.
Quando recebermos o JSON abaixo, e rodar o unmarshall, vai popular a nossa Struct. Nela, o ID vai virar routeId e o clientId vai continuar do JSON.
{"clientId":"1","routeId":"1"}

Sempre que alguem pedir para iniciar uma nova corrida, vamos ficar lendo do topico route.new-direction
E sempre que formos mandar uma posicao daonde aquela corrida esta, vamos mandar route.new-position 
{"clientId":"2","routeId":"2"}
{"clientId":"3","routeId":"3"}

Rodamos no nosso container que ira produzir a msg
[appuser@13b6ffc4dba8 ~]$ kafka-console-producer --bootstrap-server=localhost:9092 --topic=route.new-direction


Rodamos o programa do Go
com o go run main.go

E na terceira janela, que sera o consumidor, iremos rodar o comando:
[appuser@13b6ffc4dba8 ~]$ kafka-console-consumer --bootstrap-server=localhost:9092 --topic=route.new-position --group=terminal

E finalmente, na primeira janela do producer, rodamos em sequencia os seguintes comandos:
{"clientId":"1","routeId":"1"}
{"clientId":"2","routeId":"2"}        
{"clientId":"3","routeId":"3"}

Basicamente, o back-end que quando alguem falar p/ iniciar uma corrida, vai mandar o json assim para a gente. Recebemos ele (pq estamos consumindo) e dai quando comecamos a consumir
comecamos a produzir as posicoes em um outro topico.
=========================================================================================================================================
